{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client_Project_Ixchel.ipynb\r\n",
      "Client_Project_John.ipynb\r\n",
      "Client_Project_Kevin.ipynb\r\n",
      "Ixchel_Twitter.ipynb\r\n",
      "\u001b[34mTwitterScraper_duplicates\u001b[m\u001b[m\r\n",
      "Untitled.pdf\r\n",
      "converting-text-files-to-combined-dictionary.ipynb\r\n",
      "\u001b[34mdata\u001b[m\u001b[m\r\n",
      "mycsv.csv\r\n",
      "ny_temperature_Jan1.2017_Oct28.2017.ipynb\r\n",
      "saved_tweets.csv\r\n",
      "\u001b[34mtweet\u001b[m\u001b[m\r\n",
      "tweets_scrape_first_df.csv\r\n",
      "twitter_credentials.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets_scrape_first_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>datetime</th>\n",
       "      <th>has_media</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>medias</th>\n",
       "      <th>nbr_favorite</th>\n",
       "      <th>nbr_reply</th>\n",
       "      <th>nbr_retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>user_id</th>\n",
       "      <th>usernameTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267716394043465728</td>\n",
       "      <td>2012-11-11 14:52:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ConEd : NY Sandy  power   outages  slip; costs...</td>\n",
       "      <td>/RealJezzy/status/267716394043465728</td>\n",
       "      <td>504279674.0</td>\n",
       "      <td>RealJezzy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298660085255770112</td>\n",
       "      <td>2013-02-05 00:11:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@ ConEdison  \\n Power   outage  in queens</td>\n",
       "      <td>/meirBGNY/status/298660085255770112</td>\n",
       "      <td>909594764.0</td>\n",
       "      <td>meirBGNY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21860028236</td>\n",
       "      <td>2010-08-22 17:33:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Power   outage  in the Whitestone section of Q...</td>\n",
       "      <td>/olgushka1/status/21860028236</td>\n",
       "      <td>68886571.0</td>\n",
       "      <td>olgushka1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1069021302667833344</td>\n",
       "      <td>2018-12-01 19:11:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>about that  power   outage  that is now over.....</td>\n",
       "      <td>/jimcasale/status/1069021302667833344</td>\n",
       "      <td>12393522.0</td>\n",
       "      <td>jimcasale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>767077182124486656</td>\n",
       "      <td>2016-08-20 15:13:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>.@ConEdison  is responding to a  power   outag...</td>\n",
       "      <td>/NotifyNYC/status/767077182124486656</td>\n",
       "      <td>16145875.0</td>\n",
       "      <td>NotifyNYC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID             datetime has_media is_reply is_retweet  \\\n",
       "0   267716394043465728  2012-11-11 14:52:16       NaN    False      False   \n",
       "1   298660085255770112  2013-02-05 00:11:27       NaN    False      False   \n",
       "2          21860028236  2010-08-22 17:33:44       NaN    False      False   \n",
       "3  1069021302667833344  2018-12-01 19:11:54       NaN    False      False   \n",
       "4   767077182124486656  2016-08-20 15:13:46       NaN    False      False   \n",
       "\n",
       "  medias  nbr_favorite  nbr_reply  nbr_retweet  \\\n",
       "0    NaN           0.0        0.0          0.0   \n",
       "1    NaN           0.0        0.0          0.0   \n",
       "2    NaN           0.0        0.0          0.0   \n",
       "3    NaN           0.0        1.0          0.0   \n",
       "4    NaN           3.0        0.0          7.0   \n",
       "\n",
       "                                                text  \\\n",
       "0  ConEd : NY Sandy  power   outages  slip; costs...   \n",
       "1          @ ConEdison  \\n Power   outage  in queens   \n",
       "2  Power   outage  in the Whitestone section of Q...   \n",
       "3  about that  power   outage  that is now over.....   \n",
       "4  .@ConEdison  is responding to a  power   outag...   \n",
       "\n",
       "                                     url      user_id usernameTweet  \n",
       "0   /RealJezzy/status/267716394043465728  504279674.0     RealJezzy  \n",
       "1    /meirBGNY/status/298660085255770112  909594764.0      meirBGNY  \n",
       "2          /olgushka1/status/21860028236   68886571.0     olgushka1  \n",
       "3  /jimcasale/status/1069021302667833344   12393522.0     jimcasale  \n",
       "4   /NotifyNYC/status/767077182124486656   16145875.0     NotifyNYC  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                object\n",
       "datetime          object\n",
       "has_media         object\n",
       "is_reply          object\n",
       "is_retweet        object\n",
       "medias            object\n",
       "nbr_favorite     float64\n",
       "nbr_reply        float64\n",
       "nbr_retweet      float64\n",
       "text              object\n",
       "url               object\n",
       "user_id          float64\n",
       "usernameTweet     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2012-11-11 14:52:16\n",
       "1    2013-02-05 00:11:27\n",
       "2    2010-08-22 17:33:44\n",
       "3    2018-12-01 19:11:54\n",
       "4    2016-08-20 15:13:46\n",
       "5    2012-10-28 12:22:46\n",
       "6    2018-03-02 22:08:23\n",
       "7    2016-08-13 16:46:34\n",
       "8    2016-08-13 16:38:28\n",
       "9    2012-10-29 18:16:23\n",
       "10   2012-10-31 04:19:06\n",
       "11   2012-10-30 17:30:20\n",
       "Name: datetime, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df['datetime'][:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20567184\n"
     ]
    }
   ],
   "source": [
    "for i in df.datetime:\n",
    "    if i[5:7] not in ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>datetime</th>\n",
       "      <th>has_media</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>medias</th>\n",
       "      <th>nbr_favorite</th>\n",
       "      <th>nbr_reply</th>\n",
       "      <th>nbr_retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>user_id</th>\n",
       "      <th>usernameTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>/Maggie4Obama/status/108170030474203136</td>\n",
       "      <td>20567184</td>\n",
       "      <td>Maggie4Obama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ID  datetime     has_media  \\\n",
       "2808  /Maggie4Obama/status/108170030474203136  20567184  Maggie4Obama   \n",
       "\n",
       "     is_reply is_retweet medias  nbr_favorite  nbr_reply  nbr_retweet text  \\\n",
       "2808      NaN        NaN    NaN           NaN        NaN          NaN  NaN   \n",
       "\n",
       "      url  user_id usernameTweet  \n",
       "2808  NaN      NaN           NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.datetime == '20567184']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID               /Maggie4Obama/status/108170030474203136\n",
       "datetime                                        20567184\n",
       "has_media                                   Maggie4Obama\n",
       "is_reply                                             NaN\n",
       "is_retweet                                           NaN\n",
       "medias                                               NaN\n",
       "nbr_favorite                                         NaN\n",
       "nbr_reply                                            NaN\n",
       "nbr_retweet                                          NaN\n",
       "text                                                 NaN\n",
       "url                                                  NaN\n",
       "user_id                                              NaN\n",
       "usernameTweet                                        NaN\n",
       "Name: 2808, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2808]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=2808, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>datetime</th>\n",
       "      <th>has_media</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>medias</th>\n",
       "      <th>nbr_favorite</th>\n",
       "      <th>nbr_reply</th>\n",
       "      <th>nbr_retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>user_id</th>\n",
       "      <th>usernameTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, datetime, has_media, is_reply, is_retweet, medias, nbr_favorite, nbr_reply, nbr_retweet, text, url, user_id, usernameTweet]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.datetime == '20567184']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.datetime = pd.to_datetime(df.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                       object\n",
       "datetime         datetime64[ns]\n",
       "has_media                object\n",
       "is_reply                 object\n",
       "is_retweet               object\n",
       "medias                   object\n",
       "nbr_favorite            float64\n",
       "nbr_reply               float64\n",
       "nbr_retweet             float64\n",
       "text                     object\n",
       "url                      object\n",
       "user_id                 float64\n",
       "usernameTweet            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  0\n",
       "datetime            0\n",
       "has_media        4225\n",
       "is_reply            0\n",
       "is_retweet          0\n",
       "medias           4225\n",
       "nbr_favorite        0\n",
       "nbr_reply           0\n",
       "nbr_retweet         0\n",
       "text                0\n",
       "url                 1\n",
       "user_id             1\n",
       "usernameTweet       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>unique values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>4374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datetime</td>\n",
       "      <td>4254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has_media</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is_reply</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is_retweet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medias</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nbr_favorite</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nbr_reply</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nbr_retweet</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text</td>\n",
       "      <td>4116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>url</td>\n",
       "      <td>4373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_id</td>\n",
       "      <td>2533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>usernameTweet</td>\n",
       "      <td>2533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column  unique values\n",
       "0              ID           4374\n",
       "1        datetime           4254\n",
       "2       has_media              1\n",
       "3        is_reply              2\n",
       "4      is_retweet              1\n",
       "5          medias             49\n",
       "6    nbr_favorite             33\n",
       "7       nbr_reply             19\n",
       "8     nbr_retweet             45\n",
       "9            text           4116\n",
       "10            url           4373\n",
       "11        user_id           2533\n",
       "12  usernameTweet           2533"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = []\n",
    "for i in df.columns:\n",
    "    uniques = {}\n",
    "    uniques['column'] = i \n",
    "    uniques['unique values'] = df[i].nunique()\n",
    "    unique.append(uniques)\n",
    "pd.DataFrame(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Stem all of the Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tokenizer and stemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that takes in a title\n",
    "# and tokenizes and stems that title\n",
    "def stem_title(tweet):    \n",
    "    stm = PorterStemmer()\n",
    "    tokenized = word_tokenize(tweet)\n",
    "    stem_tokes = []\n",
    "    for toke in tokenized:\n",
    "        stem_tokes.append(stm.stem(toke))\n",
    "    stem_tokes\n",
    "\n",
    "    comb = ''\n",
    "    for stemmed in stem_tokes:\n",
    "        comb += stemmed + ' '\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"about that power outag that is now over ... from @ verizon `` the commerci power issu in your area may have been clear . If you still have issu with your verizon servic , click here . '' from @ conedison < cricket > \""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the function works\n",
    "stem_title(df.text[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>datetime</th>\n",
       "      <th>has_media</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>medias</th>\n",
       "      <th>nbr_favorite</th>\n",
       "      <th>nbr_reply</th>\n",
       "      <th>nbr_retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>user_id</th>\n",
       "      <th>usernameTweet</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267716394043465728</td>\n",
       "      <td>2012-11-11 14:52:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ConEd : NY Sandy  power   outages  slip; costs...</td>\n",
       "      <td>/RealJezzy/status/267716394043465728</td>\n",
       "      <td>504279674.0</td>\n",
       "      <td>RealJezzy</td>\n",
       "      <td>cone : NY sandi power outag slip ; cost could ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298660085255770112</td>\n",
       "      <td>2013-02-05 00:11:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@ ConEdison  \\n Power   outage  in queens</td>\n",
       "      <td>/meirBGNY/status/298660085255770112</td>\n",
       "      <td>909594764.0</td>\n",
       "      <td>meirBGNY</td>\n",
       "      <td>@ conedison power outag in queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21860028236</td>\n",
       "      <td>2010-08-22 17:33:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Power   outage  in the Whitestone section of Q...</td>\n",
       "      <td>/olgushka1/status/21860028236</td>\n",
       "      <td>68886571.0</td>\n",
       "      <td>olgushka1</td>\n",
       "      <td>power outag in the whiteston section of queen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1069021302667833344</td>\n",
       "      <td>2018-12-01 19:11:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>about that  power   outage  that is now over.....</td>\n",
       "      <td>/jimcasale/status/1069021302667833344</td>\n",
       "      <td>12393522.0</td>\n",
       "      <td>jimcasale</td>\n",
       "      <td>about that power outag that is now over ... fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>767077182124486656</td>\n",
       "      <td>2016-08-20 15:13:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>.@ConEdison  is responding to a  power   outag...</td>\n",
       "      <td>/NotifyNYC/status/767077182124486656</td>\n",
       "      <td>16145875.0</td>\n",
       "      <td>NotifyNYC</td>\n",
       "      <td>. @ conedison is respond to a power outag in B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID            datetime has_media is_reply is_retweet  \\\n",
       "0   267716394043465728 2012-11-11 14:52:16       NaN    False      False   \n",
       "1   298660085255770112 2013-02-05 00:11:27       NaN    False      False   \n",
       "2          21860028236 2010-08-22 17:33:44       NaN    False      False   \n",
       "3  1069021302667833344 2018-12-01 19:11:54       NaN    False      False   \n",
       "4   767077182124486656 2016-08-20 15:13:46       NaN    False      False   \n",
       "\n",
       "  medias  nbr_favorite  nbr_reply  nbr_retweet  \\\n",
       "0    NaN           0.0        0.0          0.0   \n",
       "1    NaN           0.0        0.0          0.0   \n",
       "2    NaN           0.0        0.0          0.0   \n",
       "3    NaN           0.0        1.0          0.0   \n",
       "4    NaN           3.0        0.0          7.0   \n",
       "\n",
       "                                                text  \\\n",
       "0  ConEd : NY Sandy  power   outages  slip; costs...   \n",
       "1          @ ConEdison  \\n Power   outage  in queens   \n",
       "2  Power   outage  in the Whitestone section of Q...   \n",
       "3  about that  power   outage  that is now over.....   \n",
       "4  .@ConEdison  is responding to a  power   outag...   \n",
       "\n",
       "                                     url      user_id usernameTweet  \\\n",
       "0   /RealJezzy/status/267716394043465728  504279674.0     RealJezzy   \n",
       "1    /meirBGNY/status/298660085255770112  909594764.0      meirBGNY   \n",
       "2          /olgushka1/status/21860028236   68886571.0     olgushka1   \n",
       "3  /jimcasale/status/1069021302667833344   12393522.0     jimcasale   \n",
       "4   /NotifyNYC/status/767077182124486656   16145875.0     NotifyNYC   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0  cone : NY sandi power outag slip ; cost could ...  \n",
       "1                  @ conedison power outag in queen   \n",
       "2  power outag in the whiteston section of queen ...  \n",
       "3  about that power outag that is now over ... fr...  \n",
       "4  . @ conedison is respond to a power outag in B...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column by applying the function to the title column\n",
    "# and check out the head to see if it worked\n",
    "df['stemmed_text'] = df.text.apply(stem_title)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>datetime</th>\n",
       "      <th>has_media</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>medias</th>\n",
       "      <th>nbr_favorite</th>\n",
       "      <th>nbr_reply</th>\n",
       "      <th>nbr_retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>user_id</th>\n",
       "      <th>usernameTweet</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>204532926447226880</td>\n",
       "      <td>2012-05-21 07:23:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>ConEd  is responding to a  power   outage  in ...</td>\n",
       "      <td>/NotifyNYC/status/204532926447226880</td>\n",
       "      <td>1.614588e+07</td>\n",
       "      <td>NotifyNYC</td>\n",
       "      <td>cone is respond to a power outag in SI zip cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>264374015714553858</td>\n",
       "      <td>2012-11-02 10:30:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@ hhertzof  Please check out our  outage  map ...</td>\n",
       "      <td>/ConEdison/status/264374015714553858</td>\n",
       "      <td>2.026208e+07</td>\n",
       "      <td>ConEdison</td>\n",
       "      <td>@ hhertzof pleas check out our outag map at ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>308557748671479808</td>\n",
       "      <td>2013-03-04 07:41:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@ ConEdison  Partial  power   outage  in Green...</td>\n",
       "      <td>/curlycakes/status/308557748671479808</td>\n",
       "      <td>2.760942e+08</td>\n",
       "      <td>curlycakes</td>\n",
       "      <td>@ conedison partial power outag in greenwood b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>969704423621648384</td>\n",
       "      <td>2018-03-02 17:42:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Just out of curiosity @EversourceCT , will the...</td>\n",
       "      <td>/yelenadasher/status/969704423621648384</td>\n",
       "      <td>2.791989e+09</td>\n",
       "      <td>yelenadasher</td>\n",
       "      <td>just out of curios @ eversourcect , will there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>951772242203070464</td>\n",
       "      <td>2018-01-12 06:06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>.@ConEdison  is responding to a  power   outag...</td>\n",
       "      <td>/NotifyNYC/status/951772242203070464</td>\n",
       "      <td>1.614588e+07</td>\n",
       "      <td>NotifyNYC</td>\n",
       "      <td>. @ conedison is respond to a power outag in q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID            datetime has_media is_reply is_retweet  \\\n",
       "4370  204532926447226880 2012-05-21 07:23:44       NaN    False      False   \n",
       "4371  264374015714553858 2012-11-02 10:30:51       NaN     True      False   \n",
       "4372  308557748671479808 2013-03-04 07:41:14       NaN    False      False   \n",
       "4373  969704423621648384 2018-03-02 17:42:05       NaN    False      False   \n",
       "4374  951772242203070464 2018-01-12 06:06:00       NaN    False      False   \n",
       "\n",
       "     medias  nbr_favorite  nbr_reply  nbr_retweet  \\\n",
       "4370    NaN           1.0        0.0          9.0   \n",
       "4371    NaN           0.0        0.0          1.0   \n",
       "4372    NaN           0.0        1.0          0.0   \n",
       "4373    NaN           0.0        1.0          0.0   \n",
       "4374    NaN           1.0        0.0          4.0   \n",
       "\n",
       "                                                   text  \\\n",
       "4370  ConEd  is responding to a  power   outage  in ...   \n",
       "4371  @ hhertzof  Please check out our  outage  map ...   \n",
       "4372  @ ConEdison  Partial  power   outage  in Green...   \n",
       "4373  Just out of curiosity @EversourceCT , will the...   \n",
       "4374  .@ConEdison  is responding to a  power   outag...   \n",
       "\n",
       "                                          url       user_id usernameTweet  \\\n",
       "4370     /NotifyNYC/status/204532926447226880  1.614588e+07     NotifyNYC   \n",
       "4371     /ConEdison/status/264374015714553858  2.026208e+07     ConEdison   \n",
       "4372    /curlycakes/status/308557748671479808  2.760942e+08    curlycakes   \n",
       "4373  /yelenadasher/status/969704423621648384  2.791989e+09  yelenadasher   \n",
       "4374     /NotifyNYC/status/951772242203070464  1.614588e+07     NotifyNYC   \n",
       "\n",
       "                                           stemmed_text  \n",
       "4370  cone is respond to a power outag in SI zip cod...  \n",
       "4371  @ hhertzof pleas check out our outag map at ht...  \n",
       "4372  @ conedison partial power outag in greenwood b...  \n",
       "4373  just out of curios @ eversourcect , will there...  \n",
       "4374  . @ conedison is respond to a power outag in q...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the tail, too\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('working_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorize from Unstemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "cv = CountVectorizer(stop_words='english', \n",
    "                     ngram_range=(1,1), \n",
    "                     max_features=1000\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and Transform\n",
    "sparse_df_unstemmed = cv.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0075</th>\n",
       "      <th>03</th>\n",
       "      <th>032</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>10301</th>\n",
       "      <th>10302</th>\n",
       "      <th>10304</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yhoo</th>\n",
       "      <th>yonker</th>\n",
       "      <th>york</th>\n",
       "      <th>yorker</th>\n",
       "      <th>yorktown</th>\n",
       "      <th>youtu</th>\n",
       "      <th>zajp7i</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  0075  03  032  10  100  101  10301  10302  10304  ...  yesterday  \\\n",
       "0    0     0   0    0   0    0    0      0      0      0  ...          0   \n",
       "1    0     0   0    0   0    0    0      0      0      0  ...          0   \n",
       "2    0     0   0    0   0    0    0      0      0      0  ...          0   \n",
       "3    0     0   0    0   0    0    0      0      0      0  ...          0   \n",
       "4    0     0   0    0   0    0    0      0      0      0  ...          0   \n",
       "\n",
       "   yhoo  yonker  york  yorker  yorktown  youtu  zajp7i  zip  zone  \n",
       "0     0       0     0       0         0      0       0    0     0  \n",
       "1     0       0     0       0         0      0       0    0     0  \n",
       "2     0       0     0       0         0      0       0    0     0  \n",
       "3     0       0     0       0         0      0       0    0     0  \n",
       "4     0       0     0       0         0      0       0    1     0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_df_unstemmed = pd.DataFrame(sparse_df.todense(), columns=cv.get_feature_names())\n",
    "dense_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '0075',\n",
       " '03',\n",
       " '032',\n",
       " '10',\n",
       " '100',\n",
       " '101',\n",
       " '10301',\n",
       " '10302',\n",
       " '10304',\n",
       " '10305',\n",
       " '10306',\n",
       " '10307',\n",
       " '10308',\n",
       " '10309',\n",
       " '10310',\n",
       " '10312',\n",
       " '10314',\n",
       " '10460',\n",
       " '10461',\n",
       " '10462',\n",
       " '10463',\n",
       " '10465',\n",
       " '10466',\n",
       " '10467',\n",
       " '10469',\n",
       " '10470',\n",
       " '10471',\n",
       " '11',\n",
       " '11004',\n",
       " '11203',\n",
       " '11204',\n",
       " '11205',\n",
       " '11206',\n",
       " '11207',\n",
       " '11208',\n",
       " '11209',\n",
       " '11210',\n",
       " '11214',\n",
       " '11219',\n",
       " '11220',\n",
       " '11223',\n",
       " '11224',\n",
       " '11228',\n",
       " '11229',\n",
       " '11234',\n",
       " '11235',\n",
       " '11236',\n",
       " '1131',\n",
       " '11355',\n",
       " '11356',\n",
       " '11357',\n",
       " '11358',\n",
       " '11364',\n",
       " '11365',\n",
       " '11367',\n",
       " '11368',\n",
       " '11373',\n",
       " '11377',\n",
       " '11378',\n",
       " '11379',\n",
       " '114',\n",
       " '11411',\n",
       " '11412',\n",
       " '11413',\n",
       " '11414',\n",
       " '11417',\n",
       " '11420',\n",
       " '11422',\n",
       " '11423',\n",
       " '11426',\n",
       " '11427',\n",
       " '11428',\n",
       " '11429',\n",
       " '11433',\n",
       " '11pm',\n",
       " '12',\n",
       " '13',\n",
       " '14th',\n",
       " '15',\n",
       " '16',\n",
       " '167',\n",
       " '17',\n",
       " '179',\n",
       " '1800',\n",
       " '1u2z88w',\n",
       " '20',\n",
       " '200',\n",
       " '2012',\n",
       " '2018',\n",
       " '22',\n",
       " '22lyehc',\n",
       " '24',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '26633',\n",
       " '27',\n",
       " '2h4jddc',\n",
       " '2nd',\n",
       " '30',\n",
       " '311',\n",
       " '34th',\n",
       " '36',\n",
       " '369',\n",
       " '39th',\n",
       " '40',\n",
       " '400',\n",
       " '41',\n",
       " '417',\n",
       " '436',\n",
       " '450',\n",
       " '490',\n",
       " '50',\n",
       " '500',\n",
       " '52',\n",
       " '572',\n",
       " '58',\n",
       " '6633',\n",
       " '688243',\n",
       " '6pm',\n",
       " '70',\n",
       " '700',\n",
       " '75',\n",
       " '752',\n",
       " '75coned',\n",
       " '78',\n",
       " '781',\n",
       " '80',\n",
       " '800',\n",
       " '819',\n",
       " '850',\n",
       " '888',\n",
       " '8th',\n",
       " '90',\n",
       " '911',\n",
       " '914',\n",
       " '9pm',\n",
       " 'abc7ny',\n",
       " 'able',\n",
       " 'abt',\n",
       " 'ac',\n",
       " 'access',\n",
       " 'accidental',\n",
       " 'according',\n",
       " 'account',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adilorenzotv',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'afternoon',\n",
       " 'ago',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'albans',\n",
       " 'alert',\n",
       " 'alerts',\n",
       " 'altrxo',\n",
       " 'annadale',\n",
       " 'answers',\n",
       " 'apartment',\n",
       " 'apologize',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'approx',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'apt',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'asap',\n",
       " 'asks',\n",
       " 'asl',\n",
       " 'asp',\n",
       " 'aspx',\n",
       " 'assess',\n",
       " 'assessing',\n",
       " 'assigned',\n",
       " 'assistance',\n",
       " 'assume',\n",
       " 'astoria',\n",
       " 'atus',\n",
       " 'av',\n",
       " 'ave',\n",
       " 'avenue',\n",
       " 'avoid',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'bad',\n",
       " 'bay',\n",
       " 'bayside',\n",
       " 'beach',\n",
       " 'bedford',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'bk',\n",
       " 'bklyn',\n",
       " 'blackout',\n",
       " 'blame',\n",
       " 'block',\n",
       " 'blocks',\n",
       " 'bloomberg',\n",
       " 'blue',\n",
       " 'bluelight',\n",
       " 'blvd',\n",
       " 'bnndesk',\n",
       " 'boro',\n",
       " 'borough',\n",
       " 'boroughs',\n",
       " 'breaking',\n",
       " 'breakingnews',\n",
       " 'bridge',\n",
       " 'brief',\n",
       " 'broadway',\n",
       " 'bronx',\n",
       " 'brooklyn',\n",
       " 'building',\n",
       " 'buildings',\n",
       " 'bushwick',\n",
       " 'business',\n",
       " 'bx',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'campus',\n",
       " 'cancelled',\n",
       " 'candles',\n",
       " 'car',\n",
       " 'care',\n",
       " 'case',\n",
       " 'castle',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causes',\n",
       " 'causing',\n",
       " 'cc',\n",
       " 'center',\n",
       " 'central',\n",
       " 'chappaqua',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'chelsea',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'classes',\n",
       " 'click',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closely',\n",
       " 'club',\n",
       " 'cnn',\n",
       " 'code',\n",
       " 'codes',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'com',\n",
       " 'come',\n",
       " 'coming',\n",
       " 'companies',\n",
       " 'company',\n",
       " 'conditions',\n",
       " 'cone',\n",
       " 'coned',\n",
       " 'conedison',\n",
       " 'coney',\n",
       " 'confirm',\n",
       " 'consolidated',\n",
       " 'constantly',\n",
       " 'cont',\n",
       " 'contact',\n",
       " 'continue',\n",
       " 'cool',\n",
       " 'costs',\n",
       " 'country',\n",
       " 'county',\n",
       " 'crew',\n",
       " 'crews',\n",
       " 'ct',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'customer',\n",
       " 'customercentra',\n",
       " 'customers',\n",
       " 'cut',\n",
       " 'dailyvoice',\n",
       " 'damage',\n",
       " 'damn',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'day',\n",
       " 'days',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'default',\n",
       " 'delays',\n",
       " 'details',\n",
       " 'dhh9s',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'directly',\n",
       " 'dispatched',\n",
       " 'district',\n",
       " 'dlvr',\n",
       " 'dm',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'dorp',\n",
       " 'downed',\n",
       " 'drive',\n",
       " 'dyker',\n",
       " 'dykerheights',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'east',\n",
       " 'easter',\n",
       " 'ed',\n",
       " 'ediso',\n",
       " 'edison',\n",
       " 'effecting',\n",
       " 'elderly',\n",
       " 'electric',\n",
       " 'electrical',\n",
       " 'electricity',\n",
       " 'eltingville',\n",
       " 'email',\n",
       " 'emergency',\n",
       " 'en',\n",
       " 'end',\n",
       " 'energy',\n",
       " 'entire',\n",
       " 'equipment',\n",
       " 'estimate',\n",
       " 'estimated',\n",
       " 'eta',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'ex',\n",
       " 'expect',\n",
       " 'expected',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'experiencing',\n",
       " 'explosion',\n",
       " 'facebook',\n",
       " 'faced',\n",
       " 'failure',\n",
       " 'families',\n",
       " 'far',\n",
       " 'fb',\n",
       " 'fd',\n",
       " 'fdny',\n",
       " 'feel',\n",
       " 'file',\n",
       " 'fine',\n",
       " 'fires',\n",
       " 'fix',\n",
       " 'fixed',\n",
       " 'fixing',\n",
       " 'flashlights',\n",
       " 'flatbush',\n",
       " 'flickering',\n",
       " 'flights',\n",
       " 'flooding',\n",
       " 'flushing',\n",
       " 'follow',\n",
       " 'following',\n",
       " 'food',\n",
       " 'form',\n",
       " 'free',\n",
       " 'friday',\n",
       " 'fridge',\n",
       " 'friends',\n",
       " 'ft',\n",
       " 'fuck',\n",
       " 'fulton',\n",
       " 'fun',\n",
       " 'fyi',\n",
       " 'gas',\n",
       " 'gate',\n",
       " 'gd',\n",
       " 'generator',\n",
       " 'georgelatimer37',\n",
       " 'gerritsen',\n",
       " 'getting',\n",
       " 'gg',\n",
       " 'gl',\n",
       " 'glen',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gonna',\n",
       " 'goo',\n",
       " 'good',\n",
       " 'google',\n",
       " 'got',\n",
       " 'gov',\n",
       " 'gravesend',\n",
       " 'great',\n",
       " 'grid',\n",
       " 'growing',\n",
       " 'gs',\n",
       " 'guess',\n",
       " 'guys',\n",
       " 'half',\n",
       " 'handle',\n",
       " 'handy',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hardest',\n",
       " 'harlem',\n",
       " 'harrison',\n",
       " 'hartsdale',\n",
       " 'hasn',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'head',\n",
       " 'heads',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'hearing',\n",
       " 'heat',\n",
       " 'heavy',\n",
       " 'heights',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'helping',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'hill',\n",
       " 'hills',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hmason',\n",
       " 'hold',\n",
       " 'hollis',\n",
       " 'home',\n",
       " 'homes',\n",
       " 'hook',\n",
       " 'hope',\n",
       " 'hopefully',\n",
       " 'hoping',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'houses',\n",
       " 'html',\n",
       " 'http',\n",
       " 'https',\n",
       " 'hudson',\n",
       " 'huguenot',\n",
       " 'hundreds',\n",
       " 'hurricane',\n",
       " 'hurricanesandy',\n",
       " 'ice',\n",
       " 'idea',\n",
       " 'immediately',\n",
       " 'impacted',\n",
       " 'impacting',\n",
       " 'important',\n",
       " 'including',\n",
       " 'inconvenience',\n",
       " 'increase',\n",
       " 'info',\n",
       " 'information',\n",
       " 'informative',\n",
       " 'injuries',\n",
       " 'instagr',\n",
       " 'instagram',\n",
       " 'interactive',\n",
       " 'internet',\n",
       " 'investigating',\n",
       " 'irene',\n",
       " 'island',\n",
       " 'isn',\n",
       " 'issue',\n",
       " 'issues',\n",
       " 'jamaica',\n",
       " 'jcp',\n",
       " 'jnp',\n",
       " 'job',\n",
       " 'joke',\n",
       " 'just',\n",
       " 'keeping',\n",
       " 'kills',\n",
       " 'knocked',\n",
       " 'know',\n",
       " 'laguardia',\n",
       " 'large',\n",
       " 'largest',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'latism',\n",
       " 'lawclaims',\n",
       " 'learn',\n",
       " 'left',\n",
       " 'let',\n",
       " 'letter',\n",
       " 'level',\n",
       " 'lga',\n",
       " 'lheron',\n",
       " 'life',\n",
       " 'light',\n",
       " 'lights',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'link',\n",
       " 'lipa',\n",
       " 'list',\n",
       " 'listed',\n",
       " 'little',\n",
       " 'live',\n",
       " 'living',\n",
       " 'll',\n",
       " 'local',\n",
       " 'location',\n",
       " 'lockout',\n",
       " 'lohud',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'lost',\n",
       " 'lots',\n",
       " 'love',\n",
       " 'lower',\n",
       " 'ly',\n",
       " 'main',\n",
       " 'major',\n",
       " 'majority',\n",
       " 'make',\n",
       " 'making',\n",
       " 'mamaroneck',\n",
       " 'manhattan',\n",
       " 'manhole',\n",
       " 'manor',\n",
       " 'map',\n",
       " 'maps',\n",
       " 'marine',\n",
       " 'maspeth',\n",
       " 'massive',\n",
       " 'maybe',\n",
       " 'mayor',\n",
       " 'mean',\n",
       " 'metro',\n",
       " 'middle',\n",
       " 'midwood',\n",
       " 'mikebloomberg',\n",
       " 'million',\n",
       " 'millions',\n",
       " 'min',\n",
       " 'mins',\n",
       " 'minutes',\n",
       " 'missing',\n",
       " 'mln',\n",
       " 'mn',\n",
       " 'mobile',\n",
       " 'mom',\n",
       " 'monday',\n",
       " 'month',\n",
       " 'months',\n",
       " 'morning',\n",
       " 'mp',\n",
       " 'ms',\n",
       " 'mt',\n",
       " 'mta',\n",
       " 'multilingual',\n",
       " 'multiple',\n",
       " 'nat',\n",
       " 'national',\n",
       " 'nbcnewyork',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'neck',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'neighbor',\n",
       " 'neighborhood',\n",
       " 'neighbors',\n",
       " 'nemo',\n",
       " 'new',\n",
       " 'news',\n",
       " 'news12',\n",
       " 'news12bx',\n",
       " 'news12wc',\n",
       " 'newyork',\n",
       " 'newyorkology',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nitalowey',\n",
       " 'nj',\n",
       " 'nopower',\n",
       " 'noreaster',\n",
       " 'north',\n",
       " 'northeast',\n",
       " 'noslbq',\n",
       " 'notified',\n",
       " 'notify',\n",
       " 'notifynyc',\n",
       " 'nov',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'ny',\n",
       " 'ny1',\n",
       " 'ny1coned',\n",
       " 'nyc',\n",
       " 'nyc311',\n",
       " 'nycaviation',\n",
       " 'nycem',\n",
       " 'nycmayorsoffice',\n",
       " 'nycoem',\n",
       " 'nycstorm',\n",
       " 'nyctsubway',\n",
       " 'nydailynews',\n",
       " 'nyers',\n",
       " 'nygovcuomo',\n",
       " 'nypd',\n",
       " 'nyseandg',\n",
       " 'nyseg',\n",
       " 'nytimes',\n",
       " 'nytmetro',\n",
       " 'oaks',\n",
       " 'oct',\n",
       " 'oem',\n",
       " 'office',\n",
       " 'officials',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'online',\n",
       " 'open',\n",
       " 'opinion',\n",
       " 'orange',\n",
       " 'oruconnect',\n",
       " 'outage',\n",
       " 'outages',\n",
       " 'outside',\n",
       " 'overhead',\n",
       " 'ow',\n",
       " 'ozone',\n",
       " 'page',\n",
       " 'park',\n",
       " 'parkway',\n",
       " 'partial',\n",
       " 'parts',\n",
       " 'patch',\n",
       " 'pay',\n",
       " 'paying',\n",
       " 'peekskill',\n",
       " 'pelham',\n",
       " 'people',\n",
       " 'phone',\n",
       " 'pic',\n",
       " 'place',\n",
       " 'plains',\n",
       " 'plan',\n",
       " 'plant',\n",
       " 'pleasant',\n",
       " 'pls',\n",
       " 'pm',\n",
       " 'point',\n",
       " 'police',\n",
       " 'port',\n",
       " 'possibility',\n",
       " 'possible',\n",
       " 'post',\n",
       " 'potential',\n",
       " 'pow',\n",
       " 'power',\n",
       " 'poweroutage',\n",
       " 'ppl',\n",
       " 'prepare',\n",
       " 'prepared',\n",
       " 'prepping',\n",
       " 'prevent',\n",
       " 'priority',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'provide',\n",
       " 'prsnws',\n",
       " 'pse',\n",
       " 'pseg',\n",
       " 'psegli',\n",
       " 'puts',\n",
       " 'qgxtk6',\n",
       " 'qjxum6',\n",
       " 'qn',\n",
       " 'qns',\n",
       " 'qu',\n",
       " 'queens',\n",
       " 'questions',\n",
       " 'quick',\n",
       " 'quickly',\n",
       " 'rain',\n",
       " 'random',\n",
       " 'rd',\n",
       " 'reach',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'really',\n",
       " 'realtime',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'recent',\n",
       " 'record',\n",
       " 'red',\n",
       " 'redhookd',\n",
       " 'reduce',\n",
       " 'refinery29',\n",
       " 'reg',\n",
       " 'regarding',\n",
       " 'region',\n",
       " 'reimburse',\n",
       " 'related',\n",
       " 'remember',\n",
       " 'reminds',\n",
       " 'repair',\n",
       " 'repairs',\n",
       " 'report',\n",
       " 'reported',\n",
       " 'reporting',\n",
       " 'reports',\n",
       " 'requested',\n",
       " 'requesting',\n",
       " 'residents',\n",
       " 'resolved',\n",
       " 'resources',\n",
       " 'respond',\n",
       " 'responding',\n",
       " 'response',\n",
       " 'restoration',\n",
       " 'restore',\n",
       " 'restored',\n",
       " 'restoring',\n",
       " 'result',\n",
       " 'retweet',\n",
       " 'retweeted',\n",
       " 'reut',\n",
       " 'reuters',\n",
       " 'rg',\n",
       " 'richmond',\n",
       " 'ridge',\n",
       " 'right',\n",
       " 'riverdale',\n",
       " 'road',\n",
       " 'roads',\n",
       " 'rochelle',\n",
       " 'rockland',\n",
       " 'rosedale',\n",
       " 'route',\n",
       " 'rs',\n",
       " 'rt',\n",
       " 'rueby',\n",
       " 'running',\n",
       " 'russjordan',\n",
       " 'rye',\n",
       " 'safe',\n",
       " 'safety',\n",
       " 'safetyfirst',\n",
       " 'said',\n",
       " 'sandy',\n",
       " 'sat',\n",
       " 'saturday',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'scarsdale',\n",
       " 'scattered',\n",
       " 'scene',\n",
       " 'school',\n",
       " 'scjo6o',\n",
       " 'screenshot',\n",
       " 'sea',\n",
       " 'second',\n",
       " 'section',\n",
       " 'sections',\n",
       " 'seeing',\n",
       " 'seen',\n",
       " 'send',\n",
       " 'sent',\n",
       " 'seriously',\n",
       " 'service',\n",
       " 'services',\n",
       " 'share',\n",
       " 'sheepshead',\n",
       " 'shield1631',\n",
       " 'shit',\n",
       " 'showing',\n",
       " 'shows',\n",
       " 'shut',\n",
       " 'shutting',\n",
       " 'si',\n",
       " 'sign',\n",
       " 'site',\n",
       " 'situation',\n",
       " 'sky',\n",
       " 'slip',\n",
       " 'slope',\n",
       " 'small',\n",
       " 'smart',\n",
       " 'snow',\n",
       " 'snowstorm',\n",
       " 'solution',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'sound',\n",
       " 'source',\n",
       " 'south',\n",
       " 'southern',\n",
       " 'sporadic',\n",
       " 'springville',\n",
       " 'square',\n",
       " 'st',\n",
       " 'start',\n",
       " 'started',\n",
       " 'starting',\n",
       " 'stat',\n",
       " 'state',\n",
       " 'staten',\n",
       " 'statenisland',\n",
       " 'status',\n",
       " 'stay',\n",
       " 'stew',\n",
       " 'stop',\n",
       " 'storm',\n",
       " 'stormcenter',\n",
       " 'stormcenter_ex',\n",
       " 'storms',\n",
       " 'story',\n",
       " 'street',\n",
       " 'streets',\n",
       " 'strike',\n",
       " 'stuck',\n",
       " 'substation',\n",
       " 'subway',\n",
       " 'summary',\n",
       " 'summer',\n",
       " 'sunday',\n",
       " 'super',\n",
       " 'sure',\n",
       " 'surrounding',\n",
       " 'taking',\n",
       " 'talk',\n",
       " 'tatus',\n",
       " 'tell',\n",
       " 'telling',\n",
       " 'tells',\n",
       " 'ternal',\n",
       " 'terrace',\n",
       " 'terrible',\n",
       " 'text',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thousands',\n",
       " 'throggs',\n",
       " 'throgs',\n",
       " 'thursday',\n",
       " 'thx',\n",
       " 'till',\n",
       " 'time',\n",
       " 'times',\n",
       " 'timing',\n",
       " 'tinyurl',\n",
       " 'tip',\n",
       " 'tl',\n",
       " 'tmi',\n",
       " 'today',\n",
       " 'told',\n",
       " 'tomorrow',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'total',\n",
       " 'tottenville',\n",
       " 'touch',\n",
       " 'town',\n",
       " 'track',\n",
       " 'traffic',\n",
       " 'train',\n",
       " 'trains',\n",
       " 'transformer',\n",
       " 'tree',\n",
       " 'trees',\n",
       " 'tri',\n",
       " 'tried',\n",
       " 'truck',\n",
       " 'trucks',\n",
       " 'trying',\n",
       " 'tuesday',\n",
       " 'turned',\n",
       " 'twitter',\n",
       " 'underground',\n",
       " 'union',\n",
       " 'units',\n",
       " 'update',\n",
       " 'updated',\n",
       " 'updates',\n",
       " 'updating',\n",
       " 'ur',\n",
       " 'usage',\n",
       " 'use',\n",
       " 'useful',\n",
       " 'using',\n",
       " 'utilities',\n",
       " 'utility',\n",
       " 'v0tghs',\n",
       " 'various',\n",
       " 've',\n",
       " 'video',\n",
       " 'videos',\n",
       " 'view',\n",
       " 'village',\n",
       " 'visit',\n",
       " 'voltage',\n",
       " 'vuixdz',\n",
       " 'wait',\n",
       " 'waiting',\n",
       " 'wake',\n",
       " 'wakefield',\n",
       " 'want',\n",
       " 'warning',\n",
       " 'warns',\n",
       " 'washington',\n",
       " 'wasn',\n",
       " 'watch',\n",
       " 'water',\n",
       " 'wave',\n",
       " 'way',\n",
       " 'weather',\n",
       " 'web',\n",
       " 'weboutageinfo',\n",
       " 'website',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'weeks',\n",
       " 'welcome',\n",
       " 'went',\n",
       " 'west',\n",
       " 'westchester',\n",
       " 'westchestergov',\n",
       " 'white',\n",
       " 'whitestone',\n",
       " 'wide',\n",
       " 'widespread',\n",
       " 'williams',\n",
       " 'williamsbridge',\n",
       " 'williamsburg',\n",
       " 'wind',\n",
       " 'winds',\n",
       " 'winter',\n",
       " 'wires',\n",
       " 'won',\n",
       " 'word',\n",
       " 'work',\n",
       " 'workers',\n",
       " 'working',\n",
       " 'wpix',\n",
       " 'wrong',\n",
       " 'wsjweather',\n",
       " 'wtf',\n",
       " 'www',\n",
       " 'x4jalt',\n",
       " 'yahoo',\n",
       " 'yer',\n",
       " 'yes',\n",
       " 'yesterday',\n",
       " 'yhoo',\n",
       " 'yonkers',\n",
       " 'york',\n",
       " 'yorkers',\n",
       " 'yorktown',\n",
       " 'youtu',\n",
       " 'zajp7i',\n",
       " 'zip',\n",
       " 'zips',\n",
       " 'zone',\n",
       " 'zoom']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorize from Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "cv = CountVectorizer(stop_words='english', \n",
    "                     ngram_range=(1,1), \n",
    "                     max_features=1000\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and Transform\n",
    "sparse_df_stemmed = cv.fit_transform(df.stemmed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0075</th>\n",
       "      <th>03</th>\n",
       "      <th>032</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>10301</th>\n",
       "      <th>10302</th>\n",
       "      <th>10304</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yhoo</th>\n",
       "      <th>yonker</th>\n",
       "      <th>york</th>\n",
       "      <th>yorker</th>\n",
       "      <th>yorktown</th>\n",
       "      <th>youtu</th>\n",
       "      <th>zajp7i</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  0075  03  032  10  100  101  10301  10302  10304  ...  yesterday  \\\n",
       "0    0     0   0    0   0    0    0      0      0      0  ...          0   \n",
       "1    0     0   0    0   0    0    0      0      0      0  ...          0   \n",
       "2    0     0   0    0   0    0    0      0      0      0  ...          0   \n",
       "3    0     0   0    0   0    0    0      0      0      0  ...          0   \n",
       "4    0     0   0    0   0    0    0      0      0      0  ...          0   \n",
       "\n",
       "   yhoo  yonker  york  yorker  yorktown  youtu  zajp7i  zip  zone  \n",
       "0     0       0     0       0         0      0       0    0     0  \n",
       "1     0       0     0       0         0      0       0    0     0  \n",
       "2     0       0     0       0         0      0       0    0     0  \n",
       "3     0       0     0       0         0      0       0    0     0  \n",
       "4     0       0     0       0         0      0       0    1     0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_df_stemmed = pd.DataFrame(sparse_df.todense(), columns=cv.get_feature_names())\n",
    "dense_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '0075',\n",
       " '03',\n",
       " '032',\n",
       " '10',\n",
       " '100',\n",
       " '101',\n",
       " '10301',\n",
       " '10302',\n",
       " '10304',\n",
       " '10305',\n",
       " '10306',\n",
       " '10307',\n",
       " '10308',\n",
       " '10309',\n",
       " '10310',\n",
       " '10312',\n",
       " '10314',\n",
       " '10460',\n",
       " '10461',\n",
       " '10462',\n",
       " '10463',\n",
       " '10465',\n",
       " '10466',\n",
       " '10467',\n",
       " '10469',\n",
       " '10470',\n",
       " '10471',\n",
       " '11',\n",
       " '11004',\n",
       " '11203',\n",
       " '11204',\n",
       " '11205',\n",
       " '11206',\n",
       " '11207',\n",
       " '11208',\n",
       " '11209',\n",
       " '11210',\n",
       " '11214',\n",
       " '11219',\n",
       " '11223',\n",
       " '11224',\n",
       " '11228',\n",
       " '11229',\n",
       " '11234',\n",
       " '11235',\n",
       " '11236',\n",
       " '1131',\n",
       " '11355',\n",
       " '11356',\n",
       " '11357',\n",
       " '11358',\n",
       " '11364',\n",
       " '11365',\n",
       " '11367',\n",
       " '11368',\n",
       " '11373',\n",
       " '11377',\n",
       " '11378',\n",
       " '11379',\n",
       " '114',\n",
       " '11411',\n",
       " '11412',\n",
       " '11413',\n",
       " '11414',\n",
       " '11417',\n",
       " '11420',\n",
       " '11422',\n",
       " '11423',\n",
       " '11426',\n",
       " '11427',\n",
       " '11428',\n",
       " '11429',\n",
       " '11433',\n",
       " '11pm',\n",
       " '12',\n",
       " '13',\n",
       " '14th',\n",
       " '15',\n",
       " '16',\n",
       " '167',\n",
       " '17',\n",
       " '179',\n",
       " '1800',\n",
       " '1st',\n",
       " '1u2z88w',\n",
       " '20',\n",
       " '200',\n",
       " '2012',\n",
       " '2018',\n",
       " '22',\n",
       " '22lyehc',\n",
       " '24',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '26633',\n",
       " '27',\n",
       " '29',\n",
       " '2h4jddc',\n",
       " '2nd',\n",
       " '30',\n",
       " '311',\n",
       " '34th',\n",
       " '36',\n",
       " '369',\n",
       " '39th',\n",
       " '40',\n",
       " '400',\n",
       " '41',\n",
       " '417',\n",
       " '42',\n",
       " '436',\n",
       " '450',\n",
       " '4877',\n",
       " '490',\n",
       " '50',\n",
       " '500',\n",
       " '52',\n",
       " '544',\n",
       " '572',\n",
       " '58',\n",
       " '6633',\n",
       " '688243',\n",
       " '6pm',\n",
       " '70',\n",
       " '700',\n",
       " '75',\n",
       " '752',\n",
       " '75cone',\n",
       " '7734',\n",
       " '78',\n",
       " '781',\n",
       " '7th',\n",
       " '7y56g',\n",
       " '80',\n",
       " '800',\n",
       " '819',\n",
       " '850',\n",
       " '888',\n",
       " '8th',\n",
       " '90',\n",
       " '911',\n",
       " '914',\n",
       " '9pm',\n",
       " 'abc7ni',\n",
       " 'abl',\n",
       " 'abov',\n",
       " 'abt',\n",
       " 'ac',\n",
       " 'access',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'actual',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adilorenzotv',\n",
       " 'advis',\n",
       " 'affect',\n",
       " 'afternoon',\n",
       " 'ago',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'alban',\n",
       " 'alert',\n",
       " 'alreadi',\n",
       " 'altrxo',\n",
       " 'alway',\n",
       " 'ani',\n",
       " 'annadal',\n",
       " 'announc',\n",
       " 'anoth',\n",
       " 'answer',\n",
       " 'anticip',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'apart',\n",
       " 'apolog',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'appreci',\n",
       " 'approx',\n",
       " 'approxim',\n",
       " 'apps',\n",
       " 'apt',\n",
       " 'area',\n",
       " 'arriv',\n",
       " 'asap',\n",
       " 'ask',\n",
       " 'asl',\n",
       " 'asp',\n",
       " 'aspx',\n",
       " 'assess',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'assum',\n",
       " 'astoria',\n",
       " 'atus',\n",
       " 'av',\n",
       " 'ave',\n",
       " 'avenu',\n",
       " 'avoid',\n",
       " 'awar',\n",
       " 'away',\n",
       " 'babi',\n",
       " 'bad',\n",
       " 'base',\n",
       " 'batteri',\n",
       " 'bay',\n",
       " 'baysid',\n",
       " 'beach',\n",
       " 'becaus',\n",
       " 'bedford',\n",
       " 'befor',\n",
       " 'begin',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'bk',\n",
       " 'bklyn',\n",
       " 'black',\n",
       " 'blackout',\n",
       " 'blame',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'bloomberg',\n",
       " 'blue',\n",
       " 'bluelight',\n",
       " 'blvd',\n",
       " 'bnndesk',\n",
       " 'boro',\n",
       " 'borough',\n",
       " 'break',\n",
       " 'breakingnew',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'broadway',\n",
       " 'bronx',\n",
       " 'brooklyn',\n",
       " 'brownout',\n",
       " 'build',\n",
       " 'bushwick',\n",
       " 'busi',\n",
       " 'bx',\n",
       " 'ca',\n",
       " 'cabl',\n",
       " 'campu',\n",
       " 'cancel',\n",
       " 'candl',\n",
       " 'car',\n",
       " 'care',\n",
       " 'case',\n",
       " 'castl',\n",
       " 'caus',\n",
       " 'cc',\n",
       " 'cell',\n",
       " 'center',\n",
       " 'central',\n",
       " 'chanc',\n",
       " 'chappaqua',\n",
       " 'charg',\n",
       " 'check',\n",
       " 'chelsea',\n",
       " 'citi',\n",
       " 'cl',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'clear',\n",
       " 'click',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'club',\n",
       " 'cnn',\n",
       " 'code',\n",
       " 'cold',\n",
       " 'colleg',\n",
       " 'com',\n",
       " 'come',\n",
       " 'commun',\n",
       " 'compani',\n",
       " 'complet',\n",
       " 'concern',\n",
       " 'condit',\n",
       " 'cone',\n",
       " 'coned',\n",
       " 'conedison',\n",
       " 'coney',\n",
       " 'confirm',\n",
       " 'consolid',\n",
       " 'constant',\n",
       " 'constantli',\n",
       " 'cont',\n",
       " 'contact',\n",
       " 'continu',\n",
       " 'cool',\n",
       " 'correct',\n",
       " 'cortlandt',\n",
       " 'cost',\n",
       " 'costco',\n",
       " 'counti',\n",
       " 'countri',\n",
       " 'crew',\n",
       " 'cross',\n",
       " 'ct',\n",
       " 'current',\n",
       " 'custom',\n",
       " 'customercentra',\n",
       " 'customers',\n",
       " 'cut',\n",
       " 'dailyvoic',\n",
       " 'dailyvoice',\n",
       " 'damag',\n",
       " 'damn',\n",
       " 'danger',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'date',\n",
       " 'day',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'default',\n",
       " 'degre',\n",
       " 'delay',\n",
       " 'demand',\n",
       " 'deserv',\n",
       " 'despit',\n",
       " 'dhh9',\n",
       " 'did',\n",
       " 'directli',\n",
       " 'dispatch',\n",
       " 'district',\n",
       " 'dlvr',\n",
       " 'dm',\n",
       " 'doe',\n",
       " 'don',\n",
       " 'dorp',\n",
       " 'dozen',\n",
       " 'drive',\n",
       " 'dure',\n",
       " 'dyker',\n",
       " 'dykerheight',\n",
       " 'earli',\n",
       " 'earlier',\n",
       " 'east',\n",
       " 'ed',\n",
       " 'ediso',\n",
       " 'edison',\n",
       " 'effect',\n",
       " 'elderli',\n",
       " 'electr',\n",
       " 'elev',\n",
       " 'els',\n",
       " 'eltingvil',\n",
       " 'email',\n",
       " 'emerg',\n",
       " 'en',\n",
       " 'end',\n",
       " 'entir',\n",
       " 'equip',\n",
       " 'estim',\n",
       " 'eta',\n",
       " 'event',\n",
       " 'everi',\n",
       " 'everyon',\n",
       " 'everyth',\n",
       " 'ex',\n",
       " 'expect',\n",
       " 'experi',\n",
       " 'experienc',\n",
       " 'explain',\n",
       " 'explos',\n",
       " 'extens',\n",
       " 'extra',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'fail',\n",
       " 'failur',\n",
       " 'famili',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'fb',\n",
       " 'fd',\n",
       " 'fdni',\n",
       " 'feel',\n",
       " 'file',\n",
       " 'fix',\n",
       " 'flashlight',\n",
       " 'flatbush',\n",
       " 'flicker',\n",
       " 'flight',\n",
       " 'flood',\n",
       " 'flush',\n",
       " 'follow',\n",
       " 'food',\n",
       " 'form',\n",
       " 'frankenstorm',\n",
       " 'free',\n",
       " 'freez',\n",
       " 'fresh',\n",
       " 'fri',\n",
       " 'friday',\n",
       " 'fridg',\n",
       " 'friend',\n",
       " 'ft',\n",
       " 'fuck',\n",
       " 'fulton',\n",
       " 'fun',\n",
       " 'fyi',\n",
       " 'ga',\n",
       " 'game',\n",
       " 'garden',\n",
       " 'gate',\n",
       " 'gd',\n",
       " 'gener',\n",
       " 'georgelatimer37',\n",
       " 'gerritsen',\n",
       " 'gg',\n",
       " 'gl',\n",
       " 'glen',\n",
       " 'goe',\n",
       " 'gon',\n",
       " 'goo',\n",
       " 'good',\n",
       " 'googl',\n",
       " 'got',\n",
       " 'gov',\n",
       " 'great',\n",
       " 'green',\n",
       " 'grid',\n",
       " 'grow',\n",
       " 'gs',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'ha',\n",
       " 'half',\n",
       " 'handi',\n",
       " 'handl',\n",
       " 'happen',\n",
       " 'happi',\n",
       " 'hard',\n",
       " 'hardest',\n",
       " 'harlem',\n",
       " 'harrison',\n",
       " 'haven',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heat',\n",
       " 'height',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'hill',\n",
       " 'histori',\n",
       " 'hit',\n",
       " 'hmason',\n",
       " 'hold',\n",
       " 'holli',\n",
       " 'home',\n",
       " 'hook',\n",
       " 'hope',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'hotlin',\n",
       " 'hour',\n",
       " 'hous',\n",
       " 'hr',\n",
       " 'html',\n",
       " 'http',\n",
       " 'hudson',\n",
       " 'huguenot',\n",
       " 'hundr',\n",
       " 'hurrican',\n",
       " 'hurricanesandi',\n",
       " 'ice',\n",
       " 'idea',\n",
       " 'immedi',\n",
       " 'impact',\n",
       " 'import',\n",
       " 'includ',\n",
       " 'incompet',\n",
       " 'inconveni',\n",
       " 'increas',\n",
       " 'info',\n",
       " 'inform',\n",
       " 'injuri',\n",
       " 'instagr',\n",
       " 'instagram',\n",
       " 'instal',\n",
       " 'interact',\n",
       " 'internet',\n",
       " 'intersect',\n",
       " 'investig',\n",
       " 'iren',\n",
       " 'island',\n",
       " 'issu',\n",
       " 'jackson',\n",
       " 'jamaica',\n",
       " 'jcp',\n",
       " 'jnp',\n",
       " 'job',\n",
       " 'joke',\n",
       " 'just',\n",
       " 'kid',\n",
       " 'kill',\n",
       " 'knock',\n",
       " 'know',\n",
       " 'laguardia',\n",
       " 'lake',\n",
       " 'larg',\n",
       " 'largest',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'latism',\n",
       " 'lawclaims',\n",
       " 'le',\n",
       " 'learn',\n",
       " 'leav',\n",
       " 'left',\n",
       " 'leonard',\n",
       " 'let',\n",
       " 'letter',\n",
       " 'level',\n",
       " 'lga',\n",
       " 'lheron',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'line',\n",
       " 'link',\n",
       " 'lipa',\n",
       " 'list',\n",
       " 'littl',\n",
       " 'live',\n",
       " 'll',\n",
       " 'local',\n",
       " 'locat',\n",
       " 'lockout',\n",
       " 'lohud',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'loop',\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'lower',\n",
       " 'ly',\n",
       " 'main',\n",
       " 'major',\n",
       " 'make',\n",
       " 'mamaroneck',\n",
       " 'manag',\n",
       " 'manhattan',\n",
       " 'manhol',\n",
       " 'mani',\n",
       " 'manor',\n",
       " 'map',\n",
       " 'marin',\n",
       " 'maspeth',\n",
       " 'massiv',\n",
       " 'mayb',\n",
       " 'mayor',\n",
       " 'mean',\n",
       " 'medic',\n",
       " 'messag',\n",
       " 'met',\n",
       " 'metro',\n",
       " 'middl',\n",
       " 'midwood',\n",
       " 'mikebloomberg',\n",
       " 'million',\n",
       " 'min',\n",
       " 'minut',\n",
       " 'miss',\n",
       " 'mln',\n",
       " 'mn',\n",
       " 'mobil',\n",
       " 'mom',\n",
       " 'monday',\n",
       " 'month',\n",
       " 'morn',\n",
       " 'mostli',\n",
       " 'mp',\n",
       " 'mt',\n",
       " 'mta',\n",
       " 'multilingu',\n",
       " 'multipl',\n",
       " 'na',\n",
       " 'nat',\n",
       " 'nation',\n",
       " 'nbcnewyork',\n",
       " 'near',\n",
       " 'nearli',\n",
       " 'neck',\n",
       " 'need',\n",
       " 'neighbor',\n",
       " 'neighborhood',\n",
       " 'nemo',\n",
       " 'new',\n",
       " 'news',\n",
       " 'news12',\n",
       " 'news12bx',\n",
       " 'news12wc',\n",
       " 'newyork',\n",
       " 'newyorkolog',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nitalowey',\n",
       " 'nj',\n",
       " 'noreast',\n",
       " 'north',\n",
       " 'northeast',\n",
       " 'noth',\n",
       " 'notifi',\n",
       " 'notifynyc',\n",
       " 'nov',\n",
       " 'number',\n",
       " 'ny',\n",
       " 'ny1',\n",
       " 'ny1con',\n",
       " 'nyc',\n",
       " 'nycavi',\n",
       " 'nycem',\n",
       " 'nycmayorsoffic',\n",
       " 'nycoem',\n",
       " 'nycstorm',\n",
       " 'nyctsubway',\n",
       " 'nydailynew',\n",
       " 'nyer',\n",
       " 'nygovcuomo',\n",
       " 'nypd',\n",
       " 'nyseandg',\n",
       " 'nyseg',\n",
       " 'nytmetro',\n",
       " 'oak',\n",
       " 'occur',\n",
       " 'oct',\n",
       " 'oem',\n",
       " 'offic',\n",
       " 'offici',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'onli',\n",
       " 'onlin',\n",
       " 'open',\n",
       " 'opinion',\n",
       " 'orang',\n",
       " 'order',\n",
       " 'oruconnect',\n",
       " 'outag',\n",
       " 'outage',\n",
       " 'outages',\n",
       " 'outside',\n",
       " 'overhead',\n",
       " 'ow',\n",
       " 'ozon',\n",
       " 'park',\n",
       " 'parkway',\n",
       " 'partial',\n",
       " 'patch',\n",
       " 'pay',\n",
       " 'peekskil',\n",
       " 'pelham',\n",
       " 'peopl',\n",
       " 'person',\n",
       " 'pgswpu',\n",
       " 'phone',\n",
       " 'pic',\n",
       " 'pix11new',\n",
       " 'pl',\n",
       " 'place',\n",
       " 'plain',\n",
       " 'plan',\n",
       " 'plant',\n",
       " 'pleas',\n",
       " 'pleasant',\n",
       " 'pm',\n",
       " 'point',\n",
       " 'pole',\n",
       " 'polic',\n",
       " 'port',\n",
       " 'portion',\n",
       " 'possibl',\n",
       " 'post',\n",
       " 'posts',\n",
       " 'potenti',\n",
       " 'pow',\n",
       " 'power',\n",
       " 'poweroutag',\n",
       " 'ppl',\n",
       " 'preemptiv',\n",
       " 'prep',\n",
       " 'prepar',\n",
       " 'prevent',\n",
       " 'princ',\n",
       " 'prioriti',\n",
       " 'problem',\n",
       " 'provid',\n",
       " 'prsnw',\n",
       " 'pse',\n",
       " 'pseg',\n",
       " 'psegli',\n",
       " 'qgxtk6',\n",
       " 'qjxum6',\n",
       " 'qn',\n",
       " 'qu',\n",
       " 'queen',\n",
       " 'question',\n",
       " 'quickli',\n",
       " 'rain',\n",
       " 'random',\n",
       " 'rare',\n",
       " 'rd',\n",
       " 'reach',\n",
       " 'read',\n",
       " 'readi',\n",
       " 'real',\n",
       " 'realli',\n",
       " 'realtim',\n",
       " 'reason',\n",
       " 'receiv',\n",
       " 'recent',\n",
       " 'record',\n",
       " 'red',\n",
       " 'redhookd',\n",
       " 'reduc',\n",
       " 'refinery29',\n",
       " 'reg',\n",
       " 'regard',\n",
       " 'reimburs',\n",
       " 'rel',\n",
       " 'relat',\n",
       " 'remain',\n",
       " 'remind',\n",
       " 'remov',\n",
       " 'rep',\n",
       " 'repair',\n",
       " 'report',\n",
       " 'request',\n",
       " 'resid',\n",
       " 'resolv',\n",
       " 'respond',\n",
       " 'respons',\n",
       " 'restor',\n",
       " 'result',\n",
       " 'retweet',\n",
       " 'reut',\n",
       " 'reuter',\n",
       " 'rg',\n",
       " 'richmond',\n",
       " 'ridg',\n",
       " 'right',\n",
       " 'riverdal',\n",
       " 'road',\n",
       " 'rochel',\n",
       " 'rockland',\n",
       " 'rosedal',\n",
       " 'rout',\n",
       " 'rs',\n",
       " 'rt',\n",
       " 'ruebi',\n",
       " 'run',\n",
       " 'russjordan',\n",
       " 'rye',\n",
       " 'safe',\n",
       " 'safeti',\n",
       " 'safetyfirst',\n",
       " 'said',\n",
       " 'sandi',\n",
       " 'sandy',\n",
       " 'sat',\n",
       " 'saturday',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'scarsdal',\n",
       " 'scatter',\n",
       " 'scene',\n",
       " 'school',\n",
       " 'scjo6o',\n",
       " 'screenshot',\n",
       " 'sea',\n",
       " 'second',\n",
       " 'section',\n",
       " 'seen',\n",
       " 'send',\n",
       " 'sent',\n",
       " 'servic',\n",
       " 'services',\n",
       " 'set',\n",
       " 'sever',\n",
       " 'share',\n",
       " 'sheepshead',\n",
       " 'shield1631',\n",
       " 'shit',\n",
       " 'shut',\n",
       " 'si',\n",
       " 'sign',\n",
       " 'sinc',\n",
       " 'site',\n",
       " 'situat',\n",
       " 'sky',\n",
       " 'slip',\n",
       " 'slope',\n",
       " 'sm',\n",
       " 'small',\n",
       " 'smart',\n",
       " 'snow',\n",
       " 'snowstorm',\n",
       " 'soho',\n",
       " 'solut',\n",
       " 'someon',\n",
       " 'someth',\n",
       " 'soon',\n",
       " 'sorri',\n",
       " 'sound',\n",
       " 'sourc',\n",
       " 'south',\n",
       " 'southern',\n",
       " 'speak',\n",
       " 'spokesman',\n",
       " 'sporad',\n",
       " 'springvil',\n",
       " 'squar',\n",
       " 'st',\n",
       " 'start',\n",
       " 'stat',\n",
       " 'state',\n",
       " 'staten',\n",
       " 'statenisland',\n",
       " 'statu',\n",
       " 'status',\n",
       " 'stay',\n",
       " 'stew',\n",
       " 'stop',\n",
       " 'stori',\n",
       " 'storm',\n",
       " 'stormcenter',\n",
       " 'stormcenter_ex',\n",
       " 'story',\n",
       " 'street',\n",
       " 'stretch',\n",
       " 'strike',\n",
       " 'stuck',\n",
       " 'substat',\n",
       " 'subway',\n",
       " 'suck',\n",
       " 'suffer',\n",
       " 'summari',\n",
       " 'summer',\n",
       " 'sunday',\n",
       " 'super',\n",
       " 'sure',\n",
       " 'surg',\n",
       " 'surround',\n",
       " 'svc',\n",
       " 'talk',\n",
       " 'tarrytown',\n",
       " 'tatus',\n",
       " 'tell',\n",
       " 'temp',\n",
       " 'term',\n",
       " 'ternal',\n",
       " 'terrac',\n",
       " 'terribl',\n",
       " 'text',\n",
       " 'thank',\n",
       " 'thi',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'thousand',\n",
       " 'throg',\n",
       " 'throgg',\n",
       " 'thursday',\n",
       " 'thx',\n",
       " 'ticket',\n",
       " 'till',\n",
       " 'tim',\n",
       " 'time',\n",
       " 'tinyurl',\n",
       " 'tip',\n",
       " 'tl',\n",
       " 'tmi',\n",
       " 'today',\n",
       " 'togeth',\n",
       " 'told',\n",
       " 'tomorrow',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'total',\n",
       " 'totten',\n",
       " 'tottenvil',\n",
       " 'touch',\n",
       " 'town',\n",
       " 'track',\n",
       " 'traffic',\n",
       " 'train',\n",
       " 'transform',\n",
       " 'travel',\n",
       " 'tree',\n",
       " 'tri',\n",
       " 'truck',\n",
       " 'tuesday',\n",
       " 'turn',\n",
       " 'tweet',\n",
       " 'twitter',\n",
       " 'unaccept',\n",
       " 'underground',\n",
       " 'union',\n",
       " 'unit',\n",
       " 'unless',\n",
       " 'updat',\n",
       " 'upgrad',\n",
       " 'ur',\n",
       " 'urg',\n",
       " 'usa',\n",
       " 'usag',\n",
       " 'use',\n",
       " 'util',\n",
       " 'uw',\n",
       " 'v0tgh',\n",
       " 'valley',\n",
       " 'variou',\n",
       " 've',\n",
       " 'veri',\n",
       " 'video',\n",
       " 'villag',\n",
       " 'visit',\n",
       " 'voltag',\n",
       " 'vuixdz',\n",
       " 'wa',\n",
       " 'wait',\n",
       " 'wake',\n",
       " 'wakefield',\n",
       " 'want',\n",
       " 'warn',\n",
       " 'washington',\n",
       " 'watch',\n",
       " 'water',\n",
       " 'wave',\n",
       " 'way',\n",
       " 'weather',\n",
       " 'web',\n",
       " 'weboutageinfo',\n",
       " 'websit',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'went',\n",
       " 'west',\n",
       " 'westchest',\n",
       " 'westchester',\n",
       " 'westchestergov',\n",
       " 'whi',\n",
       " 'white',\n",
       " 'whiteston',\n",
       " 'wide',\n",
       " 'widespread',\n",
       " 'william',\n",
       " 'williamsbridg',\n",
       " 'williamsburg',\n",
       " 'win',\n",
       " 'wind',\n",
       " 'winter',\n",
       " 'wire',\n",
       " 'wo',\n",
       " 'wonder',\n",
       " 'word',\n",
       " 'work',\n",
       " 'worker',\n",
       " 'world',\n",
       " 'wow',\n",
       " 'wpix',\n",
       " 'wrong',\n",
       " 'wsjweather',\n",
       " 'wtf',\n",
       " 'www',\n",
       " 'x4jalt',\n",
       " 'yahoo',\n",
       " 'ye',\n",
       " 'year',\n",
       " 'yesterday',\n",
       " 'yhoo',\n",
       " 'yonker',\n",
       " 'york',\n",
       " 'yorker',\n",
       " 'yorktown',\n",
       " 'youtu',\n",
       " 'zajp7i',\n",
       " 'zip',\n",
       " 'zone']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "km = KMeans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=8, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sc = ss.fit_transform(dense_df_unstemmed)\n",
    "km.fit(X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0189908773190813"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(sparse_df_unstemmed, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
